import os
import zipfile
import gdown

import streamlit as st

from langchain_upstage import ChatUpstage, UpstageEmbeddings
from langchain_community.vectorstores import Chroma
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnablePassthrough


# âœ… set_page_configëŠ” ê°€ëŠ¥í•œ í•œ ìœ„ì—ì„œ 1ë²ˆë§Œ
st.set_page_config(page_title="í•™êµë„ì„œê´€ ë…ì„œí™œë™ ì§€ì› ì±—ë´‡", page_icon="ğŸ“š")


# ğŸ”‘ API KEY
if "UPSTAGE_API_KEY" in st.secrets:
    os.environ["UPSTAGE_API_KEY"] = st.secrets["UPSTAGE_API_KEY"]


def download_and_unpack_chroma_db():
    file_id = "1XXyTjn8-yxa795E3k4stplJfNdFDyro2"
    url = f"https://drive.google.com/uc?id={file_id}"

    if os.path.exists("chroma_db") and os.listdir("chroma_db"):
        return

    if os.path.exists("chroma_db.zip"):
        os.remove("chroma_db.zip")

    st.write("â¬‡ ë²¡í„° DB(chroma_db.zip)ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘ì…ë‹ˆë‹¤...")
    gdown.download(url, "chroma_db.zip", quiet=False)

    if os.path.getsize("chroma_db.zip") < 1000:
        st.error("âŒ chroma_db.zip íŒŒì¼ ì˜¤ë¥˜")
        return

    with zipfile.ZipFile("chroma_db.zip", "r") as zip_ref:
        zip_ref.extractall(".")


@st.cache_resource
def load_rag_chain():
    download_and_unpack_chroma_db()

    embeddings = UpstageEmbeddings(model="solar-embedding-1-large")
    vectorstore = Chroma(
        embedding_function=embeddings,
        persist_directory="chroma_db"
    )

    retriever = vectorstore.as_retriever(search_kwargs={"k": 4})

    # âœ… í•™ìƒ ì •ë³´(profile) + ë©”ë‰´(menu) ë°˜ì˜
    prompt = ChatPromptTemplate.from_template(
        """
ë„ˆëŠ” í•™êµë„ì„œê´€ì—ì„œ í•™ìƒë“¤ì˜ ë…ì„œí™œë™ì„ ë„ì™€ì£¼ëŠ” ë„ìš°ë¯¸ì•¼.
ì•„ë˜ ì°¸ê³  ë¬¸ì„œë¥¼ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µí•´ì¤˜.

[í˜„ì¬ ê¸°ëŠ¥]
{menu}

[í•™ìƒ ì •ë³´]
{profile}

ì§€ì¹¨:
- 'ì±… ì¶”ì²œ' ì§ˆë¬¸ì´ë©´ í•™ìƒ ì •ë³´(í•™ë…„/ê´€ì‹¬/ì½ê¸°ìˆ˜ì¤€)ë¥¼ ë°˜ì˜í•´ ì¶”ì²œ
- ì •ë³´ê°€ ì—†ìœ¼ë©´ ì¼ë°˜ì ì¸ ê¸°ì¤€ìœ¼ë¡œ ì•ˆë‚´
- ë¬¸ì„œì— ì—†ìœ¼ë©´ ëª¨ë¥¸ë‹¤ê³  ì†”ì§íˆ ë§í•´

[ì°¸ê³  ë¬¸ì„œ]
{context}

[ì§ˆë¬¸]
{question}
        """
    )

    llm = ChatUpstage()

    rag_chain = (
        {
            "context": lambda x: retriever.invoke(x["question"]),
            "question": lambda x: x["question"],
            "profile": lambda x: x["profile"],
            "menu": lambda x: x["menu"],
        }
        | prompt
        | llm
        | StrOutputParser()
    )

    return rag_chain


rag_chain = load_rag_chain()


# -------------------------
# UI
# -------------------------
st.title("ğŸ“š í•™êµë„ì„œê´€ ë…ì„œí™œë™ ì§€ì› ì±—ë´‡")
st.caption("ë„ì„œê´€ ì†Œì¥ìë£Œì™€ ë…ì„œêµìœ¡ ìë£Œë¥¼ ì°¸ê³ í•˜ì—¬ ë…ì„œ ê´€ë ¨ ì§ˆë¬¸ì— ë‹µí•´ì£¼ëŠ” ì±—ë´‡ì…ë‹ˆë‹¤.")


with st.sidebar:
    st.subheader("ğŸ“Œ ë©”ë‰´")

    menu = st.radio(
        "ê¸°ëŠ¥ ì„ íƒ",
        ["ë„ì„œê´€ ì´ìš© ì•ˆë‚´", "ì±… ì¶”ì²œ", "ë…ì„œí™œë™"],
        index=0,
        label_visibility="collapsed"
    )

    st.divider()

    # ê¸°ë³¸ê°’
    grade = "ì—†ìŒ"
    interest = "ì—†ìŒ"
    level = "ì—†ìŒ"

    if menu == "ë„ì„œê´€ ì´ìš© ì•ˆë‚´":
        st.markdown("**ë„ì„œê´€ ì´ìš© ë°©ë²• ì•ˆë‚´**")
        st.caption("ëŒ€ì¶œÂ·ë°˜ë‚©Â·ì—°ì¥Â·ì´ìš© ê·œì • ë“±")

    elif menu == "ì±… ì¶”ì²œ":
        st.markdown("**í•™ìƒ í”„ë¡œí•„ ê¸°ë°˜ ì±… ì¶”ì²œ**")

        grade = st.selectbox("í•™ë…„", ["ì´ˆë“±", "ì¤‘ë“±", "ê³ ë“±"])
        interest = st.text_input("ê´€ì‹¬ ì£¼ì œ (ì˜ˆ: ìš°ì •, ì¶”ë¦¬, ê³¼í•™)", "")
        level = st.select_slider(
            "ì½ê¸° ìˆ˜ì¤€",
            options=["ì‰¬ì›€", "ë³´í†µ", "ì–´ë ¤ì›€"],
            value="ë³´í†µ"
        )

        st.caption("â€» ì…ë ¥í• ìˆ˜ë¡ ì¶”ì²œ ì •í™•ë„ê°€ ë†’ì•„ì§‘ë‹ˆë‹¤.")

    else:
        st.markdown("**ë…ì„œí™œë™ ì§€ì›**")
        st.caption("ğŸ“– ì½ê¸° í™œë™ ex) ì˜¬ë°”ë¥¸ ë…ì„œë²•")
        st.caption("âœï¸ ì“°ê¸° í™œë™ ex) ë…ì„œê°ìƒë¬¸, ì„œí‰")
        st.caption("ğŸ‘¥ ê·¸ë£¹ í™œë™ ex) ë…ì„œí† ë¡ , ë…ì„œë™ì•„ë¦¬")


# ì±„íŒ… íˆìŠ¤í† ë¦¬
if "messages" not in st.session_state:
    st.session_state["messages"] = []

for msg in st.session_state["messages"]:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])


user_input = st.chat_input("ê¶ê¸ˆí•œ ê²ƒì„ ì…ë ¥í•˜ì„¸ìš”.")

if user_input:
    st.session_state["messages"].append({"role": "user", "content": user_input})
    with st.chat_message("user"):
        st.markdown(user_input)

    profile = f"í•™ë…„:{grade}, ê´€ì‹¬:{interest or 'ì—†ìŒ'}, ì½ê¸°ìˆ˜ì¤€:{level}"

    # âœ… (2) í”„ë¡œí•„ì„ ì§ˆë¬¸ í…ìŠ¤íŠ¸ì— ì„ì–´ì„œ retrieverì—ë„ ì˜í–¥
    # âœ… (3) ë‹¨, 'ì±… ì¶”ì²œ' íƒ­ì—ì„œë§Œ ì ìš©
    if menu == "ì±… ì¶”ì²œ":
        question_for_rag = f"{user_input}\n\n[í•™ìƒ ì •ë³´] {profile}"
    else:
        question_for_rag = user_input

    with st.chat_message("assistant"):
        with st.spinner("ìƒê° ì¤‘ì…ë‹ˆë‹¤..."):
            answer = rag_chain.invoke({
                "question": question_for_rag,   # âœ… ì—¬ê¸°ë§Œ ë³€ê²½
                "profile": profile,
                "menu": menu
            })
            st.markdown(answer)

    st.session_state["messages"].append({"role": "assistant", "content": answer})

